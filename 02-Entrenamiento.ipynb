{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento\n",
    "**Solucionado** Posibles soluciones a la indeterminación de la pérdida en el entrenamiento\n",
    "[1](https://github.com/keras-team/keras/issues/2530)\n",
    "[2](https://stackoverflow.com/questions/37232782/nan-loss-when-training-regression-network)\n",
    "[3](https://github.com/keras-team/keras/issues/2134)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subtract_mean registered\n",
      "minmax registered\n",
      "znormalization registered\n"
     ]
    }
   ],
   "source": [
    "# Default python libraries\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Third party\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from model_training import (\n",
    "    LoadTimeSerie,\n",
    "    Preprocessing,\n",
    "    DataGenerator,\n",
    "    ModelLoader\n",
    ")\n",
    "\n",
    "from model_training.utils import (\n",
    "    fromJSON,\n",
    "    asJSON,\n",
    "    set_logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fijar semilla\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio donde guardar resultados de entrenamiento\n",
    "path_save_train_results = Path(\"train_results\")\n",
    "path_save_train_results.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear logger para el entrenamiento\n",
    "logger = set_logger(path_log = \"train_results/logs_training.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos\n",
    "logger.info(\"Cargando datos para entrenamiento.\")\n",
    "\n",
    "list_train = fromJSON(\"data/list_train.json\")\n",
    "list_val   = fromJSON(\"data/list_val.json\")\n",
    "list_test  = fromJSON(\"data/list_test.json\")\n",
    "labels = fromJSON(\"data/labels.json\")\n",
    "data_config = fromJSON(\"data/split_config.json\")\n",
    "ts_config = fromJSON(\"time_series/time_series_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Definiendo features para input y output.\")\n",
    "# nombre de las columnas de las series de tiempo\n",
    "features = ts_config.get(\"features\")\n",
    "\n",
    "# Features para \n",
    "input_features  = features               # input\n",
    "output_features = [\"sales_usd_day\"]      # output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 'LSTM2_X30_y1' cargado correctamente\n",
      "Pipeline configuration saved at 'train_results/preprocessing.json'\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Definiendo configuracion de entrenamiento\")\n",
    "# referencia a las columas de la serie de tiempo \n",
    "idx_input_features = [features.index(out) for out in input_features] # input\n",
    "idx_output_features = [features.index(out) for out in output_features] # output\n",
    "\n",
    "# Modelo a utilizar\n",
    "model_name = 'LSTM2_X30_y1'#'LSTM1_X30_y1' # Modelo en '/model_training/models'. Estructura <NOMBRE RED>_X<largo serie input>_y<neuronas capa salida>\n",
    "weights_path=None # Pesos para inicializar la red\n",
    "output_layer = 'linear' # funcion de activacion en la capa de salida. None -> activacion lineal f(x)=x\n",
    "n_output = None # neuronas en la ultima capa. None -> len(order_output_model)\n",
    "model_loader = ModelLoader()\n",
    "model = model_loader(model_name)\n",
    "logger.info(f\"Modelo {model_name!r} cargado.\")\n",
    "\n",
    "# Batches (batch_size, len_signal, len_feature)  \n",
    "epochs = 2\n",
    "batch_size = 128\n",
    "logger.info(f\"Batch {batch_size} y epocas {epochs}\")\n",
    "\n",
    "len_input = data_config.get(\"len_input\") # largo del input \n",
    "len_output = data_config.get(\"len_output\") # largo del output, 1 para este problema\n",
    "logger.info(f\"len_input={len_input}, len_output={len_output}.\")\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(\n",
    "    learning_rate=0.003,\n",
    "    rho=0.9,\n",
    "    momentum=0.0,\n",
    "    epsilon=1e-07,\n",
    "    centered=False,\n",
    "    name=\"RMSprop\"\n",
    ")\n",
    "name_optimizer = \"RMSprop\"\n",
    "logger.info(f\"Optimizador '{optimizer}'\")\n",
    "\n",
    "# Funcion de perdida\n",
    "loss = tf.keras.losses.MeanSquaredError(\n",
    "    reduction=\"auto\", \n",
    "    name=\"mean_squared_error\"\n",
    ")\n",
    "name_loss = \"mse\"\n",
    "logger.info(f\"Funcion de perdida '{loss}'\")\n",
    "\n",
    "# Preprocesamiento\n",
    "list_min = ts_config.get(\"list_min\")\n",
    "list_max = ts_config.get(\"list_max\")\n",
    "list_std = ts_config.get(\"list_std\")\n",
    "list_mean = ts_config.get(\"list_mean\")\n",
    "\n",
    "# Para X\n",
    "preprocessing = Preprocessing([\n",
    "    #(\"minmax\", dict(axis_signal=0, list_min=list_min, list_max=list_max ))\n",
    "    (\"znormalization\", dict(axis_signal=0, list_mean=list_mean, list_std=list_std ))\n",
    "])\n",
    "preprocessing.asJSON(\"train_results/preprocessing.json\")\n",
    "logger.info(f\"Guardando preprocessing.json\")\n",
    "\n",
    "# Para y: mismo de X pero en menos features\n",
    "preprocessing_y = Preprocessing([\n",
    "    #(\"minmax\", dict(axis_signal=0, list_min=list_min[idx_output_features[0]], list_max=list_max[idx_output_features[0]] ))\n",
    "    (\"znormalization\", dict(axis_signal=0, list_mean=list_mean[idx_output_features[0]], list_std=list_std[idx_output_features[0]] ))\n",
    "])\n",
    "\n",
    "# Cargar DataGenerator\n",
    "logger.info(\"Definiendo configuracion general del DataGenerator\")\n",
    "inputs_data_gen = dict(\n",
    "    labels=labels,\n",
    "    idx_feature_y = idx_output_features,\n",
    "    file_loader = LoadTimeSerie(),\n",
    "    preprocessing = preprocessing,\n",
    "    preprocessing_y = preprocessing_y,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "logger.info(\"Instanciando DataGenerator para entrenamiento\")\n",
    "train_gen = DataGenerator(\n",
    "    list_id_ts=list_train,\n",
    "    shuffle=True, # Se recomienda aleatorizar en el entrenamiento\n",
    "    **inputs_data_gen\n",
    ")\n",
    "\n",
    "logger.info(\"Instanciando DataGenerator para validacion\")\n",
    "val_gen = DataGenerator(\n",
    "    list_id_ts=list_val,\n",
    "    shuffle=False, # No es necesario aleatorizar para la validacion\n",
    "    **inputs_data_gen\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Compilando modelo\")\n",
    "model.compile(optimizer=optimizer, loss=loss)#, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Guardando arquitectura\")\n",
    "model_json = model.to_json()\n",
    "architecture = f\"architecture-{model_name}-{output_layer}.json\"\n",
    "path_save_model = f\"train_results/{architecture}\"\n",
    "with open(path_save_model, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "logger.info(f\"Arquitectura guardada en {path_save_model!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Agregando callbacks\")\n",
    "# ModelCheckpoint\n",
    "weights_file = f'{path_save_train_results}/weights-{model_name}-' + 'epoch{epoch:03d}-val_loss{val_loss:.3f}.hdf5'\n",
    "\n",
    "# Tensorboard\n",
    "now = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = os.path.join(\n",
    "    \"logs\",\n",
    "    f\"{model_name}-{now}\",\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=weights_file, save_best_only=True, save_weights_only=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=0.0001),\n",
    "    tf.keras.callbacks.EarlyStopping(patience=10),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "687/687 [==============================] - 22s 32ms/step - loss: 0.4606 - val_loss: 0.1822 - lr: 0.0030\n",
      "Epoch 2/2\n",
      "687/687 [==============================] - 21s 31ms/step - loss: 0.3808 - val_loss: 0.1730 - lr: 0.0030\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Comenzando entrenamiento.\")\n",
    "history_train = model.fit(\n",
    "    x=train_gen,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_gen,\n",
    "    callbacks = callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Generando configuracion de entrenamiento\")\n",
    "\n",
    "training_config = dict(\n",
    "        input_features  = features,\n",
    "        output_features = [\"venta_clp_dia\"],\n",
    "        batch_size = batch_size,\n",
    "        epochs = epochs,\n",
    "        loss = name_loss,\n",
    "        optimizer = name_optimizer,\n",
    "        model_name = model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_features': ['venta_unidades_dia', 'venta_clp_dia', 'is_promo'],\n",
       " 'output_features': ['venta_clp_dia'],\n",
       " 'batch_size': 128,\n",
       " 'epochs': 2,\n",
       " 'loss': 'mse',\n",
       " 'optimizer': 'RMSprop',\n",
       " 'model_name': 'LSTM2_X30_y1'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_save_training_config = path_save_train_results.joinpath(\"training_config.json\")\n",
    "asJSON(training_config, str(path_save_training_config),sort_keys=False)\n",
    "logger.info(\"Configuracion de entrenamiento guardada\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}